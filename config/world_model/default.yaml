_target_: models.TransformerConfig
tokens_per_block: 17
max_blocks: 20
attention: 'causal'
num_layers: 10
num_heads: 4
embed_dim: 256
embed_pdrop: 0.1
resid_pdrop: 0.1
attn_pdrop: 0.1
model: 'irisXL-discrete'
dyn_embed_dim: 256
dyn_num_heads: 4
dyn_num_layers: 10
dyn_feedforward_dim: 1024
dyn_head_dim: 64
dyn_z_dims: [512, 512, 512, 512]
dyn_reward_dims: [256, 256, 256, 256]
dyn_discount_dims: [256, 256, 256, 256]
dyn_input_rewards: True
dyn_input_discounts: False
dyn_act: 'silu'
dyn_norm: 'none'
dyn_dropout: 0.1
dyn_lr: 1e-4
dyn_wd: 1e-6
dyn_eps: 1e-5
dyn_grad_clip: 100
dyn_z_coef: 1
dyn_reward_coef: 10
dyn_discount_coef: 50
wm_batch_size: 100
wm_sequence_length: 340
wm_train_steps: 1
wm_memory_length: 17
wm_discount_threshold: 0.1
regularization_post_quant: False
regularization_tokens: False
regularization_embeddings: False
embedding_input: False