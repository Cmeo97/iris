defaults:
  - _self_
  - tokenizer: slot_attn_with_samvit
  - image_decoder: default
  - world_model: slot_attn
  - actor_critic: dinosaur
  - env: default
  - datasets: default

# hydra:
#   run:
#     dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    #dir: /home/mila/c/cristian.meo/scratch/iris_log/${env.train.id}/${world_model.model}/${now:%Y-%m-%d}/${now:%H-%M-%S}

wandb:
  mode: online
  # project: OC-IRIS
  # entity: cmeo97
  # name: OC-iris-trial
  # group: iris
  project: IRIS-dinosaur
  entity: null
  name: null
  group: null
  tags: null
  notes: null


initialization:
  # path_to_checkpoint: /space/cristianmeo/iris/outputs/OC-extractor/checkpoints/last.pt
  path_to_checkpoint: null
  load_tokenizer: True
  load_world_model: False
  load_actor_critic: False


# initialization:
#   path_to_checkpoint: checkpoints/last.pt
#   load_tokenizer: True
#   load_world_model: False
#   load_actor_critic: False

common:
  epochs: 300
  device: cuda:5
  do_checkpoint: True
  seed: 0
  sequence_length: ${world_model.max_blocks}
  resume: False # set by resume.sh script only.
  slot_based: True
  use_pretrained: False
  use_amp: True

collection:
  train:
    num_envs: 1
    stop_after_epochs: 600
    num_episodes_to_save: 10
    config:
      epsilon: 0.01
      should_sample: True
      temperature: 1.0
      num_steps: 200
      burn_in: ${training.actor_critic.burn_in}
  test:
    num_envs: 8
    num_episodes_to_save: ${collection.train.num_episodes_to_save}
    config:
      epsilon: 0.0
      should_sample: True
      temperature: 0.5
      num_episodes: 16
      burn_in: ${training.actor_critic.burn_in}

training:
  should: True
  learning_rate: 0.0001
  sampling_weights: [0.125, 0.125, 0.25, 0.5]
  tokenizer:
    learning_rate: 0.0002
    batch_num_samples: 16
    grad_acc_steps: 1
    max_grad_norm: 1.0
    start_after_epochs: 25
    steps_per_epoch: 200
  world_model:
    batch_num_samples: 16
    grad_acc_steps: 4
    max_grad_norm: 10.0
    weight_decay: 0.01
    start_after_epochs: 100
    steps_per_epoch: 200
  actor_critic:
    batch_num_samples: 64
    grad_acc_steps: 4
    max_grad_norm: 10.0
    start_after_epochs: 120
    steps_per_epoch: 200
    imagine_horizon: ${common.sequence_length}
    burn_in: 20
    gamma: 0.995
    lambda_: 0.95
    entropy_weight: 0.001
  image_decoder:
    learning_rate: 0.0002
    batch_num_samples: 16
    grad_acc_steps: 1
    max_grad_norm: 1.0
    start_after_epochs: 25
    steps_per_epoch: 200

evaluation:
  should: True
  every: 10
  tokenizer:
    batch_num_samples: ${training.tokenizer.batch_num_samples}
    start_after_epochs: ${training.tokenizer.start_after_epochs}
    save_reconstructions: True
  world_model:
    batch_num_samples: ${training.world_model.batch_num_samples}
    start_after_epochs: ${training.world_model.start_after_epochs}
  actor_critic:
    num_episodes_to_save: ${training.actor_critic.batch_num_samples}
    horizon: ${training.actor_critic.imagine_horizon}
    start_after_epochs: ${training.actor_critic.start_after_epochs}
